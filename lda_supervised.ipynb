{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitvenvvenv92989b579a004056b111a412eddd53db",
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Configurables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = [\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"]"
   ]
  },
  {
   "source": [
    "# Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2categories() -> dict:\n",
    "    o = dict()\n",
    "    for idx, cat in enumerate(CATEGORIES):\n",
    "        o[idx] = cat\n",
    "    return o\n",
    "\n",
    "def categories2id() -> dict:\n",
    "    o = dict()\n",
    "    for idx, cat in enumerate(CATEGORIES):\n",
    "        o[cat] = idx\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords, strip_multiple_whitespaces, strip_punctuation2, preprocess_string, strip_short, strip_numeric, stem_text, strip_tags\n",
    "\n",
    "# Define custom filters\n",
    "CUSTOM_FILTERS = [lambda x:\n",
    "                  x.lower(),\n",
    "                  strip_multiple_whitespaces,\n",
    "                  strip_numeric,\n",
    "                  remove_stopwords,\n",
    "                  strip_short,\n",
    "                  stem_text,\n",
    "                  strip_tags,\n",
    "                  strip_punctuation2\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "STOP_WORDS = stopwords.words('english')\n",
    "\n",
    "def load_stopwords() -> list:\n",
    "    stop_words = []\n",
    "    with open(\"stopword\", \"r\") as fh:\n",
    "        words = fh.readlines()\n",
    "        for word in words:\n",
    "            word = word.rstrip(\"\\n\").strip()\n",
    "            stop_words.append(word)\n",
    "    return stop_words\n",
    "\n",
    "STOP_WORDS.extend(load_stopwords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2225 articles loaded. 0 articles ignored due to non-existing categories.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "DATA_PATH = \"./BBC News Summary/BBC News Summary/News Articles\"\n",
    "\n",
    "# Load the text from directory, identify category from folder and \n",
    "# put the texts in a list in the order of the categories specified in configurables\n",
    "def get_texts() -> (list, list, list):\n",
    "    category_text_map = defaultdict(list)\n",
    "    texts = []\n",
    "    categories = []\n",
    "    ignored = []\n",
    "    ignore = False\n",
    "    for root, _, files in os.walk(DATA_PATH):\n",
    "        if len(files) == 0: continue\n",
    "        category = root.split('/')[-1].lower()\n",
    "        if category not in CATEGORIES:\n",
    "            print(\"Category {} is not in pre-set categories. Please add it in and re-run the program!\".format(category))\n",
    "            ignore = True\n",
    "        else:\n",
    "            ignore = False\n",
    "        for f in files:\n",
    "            txt_path = os.path.join(root, f)\n",
    "            text = \"\"\n",
    "            with open(txt_path, 'r', encoding=\"ISO-8859-1\") as fh:\n",
    "                lines = fh.readlines()\n",
    "                for line in lines:\n",
    "                    text += line\n",
    "            if ignore:\n",
    "                ignored.append(text)\n",
    "            else:\n",
    "                category_text_map[category].append(text)\n",
    "    \n",
    "    for cat in CATEGORIES:\n",
    "        files = category_text_map[cat]\n",
    "        texts.extend(files)\n",
    "        categories.extend([categories2id()[cat] for _ in range(len(files))])\n",
    "\n",
    "    if len(texts) != len(categories):\n",
    "        raise Exception(\"Number of articles and number of target categories do not have the same length: [{} != {}]\".format(len(texts), len(categories)))\n",
    "\n",
    "    return texts, categories, ignored\n",
    "\n",
    "\n",
    "def clean_texts(texts: list) -> list:\n",
    "    clean_texts = []\n",
    "    for text in texts:\n",
    "        processed_texts = preprocess_string(text, CUSTOM_FILTERS)\n",
    "        processed_texts = [w for w in processed_texts if not w in STOP_WORDS]\n",
    "        clean_texts.append(processed_texts)\n",
    "    return clean_texts\n",
    "\n",
    "texts, categories, ignored = get_texts()\n",
    "texts = clean_texts(texts)\n",
    "print(\"{} articles loaded. {} articles ignored due to non-existing categories.\".format(len(texts), len(ignored)))"
   ]
  },
  {
   "source": [
    "# Get Corpus"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "), (3037, 1), (3059, 1), (3103, 2), (3128, 1), (3187, 1), (3214, 2), (3258, 1), (3302, 3), (3318, 12), (3321, 2), (3324, 1), (3330, 2), (3529, 1), (3545, 1), (3692, 1), (3703, 1), (3753, 2), (3805, 3), (3887, 2), (3972, 4), (4034, 1), (4105, 1), (4164, 1), (4166, 4), (4180, 1), (4559, 2), (4567, 1), (4575, 2), (4587, 1)], [(9, 1), (26, 3), (33, 1), (66, 1), (68, 1), (70, 1), (85, 1), (99, 1), (103, 1), (106, 1), (182, 1), (191, 1), (200, 1), (202, 1), (209, 1), (247, 1), (250, 1), (263, 1), (284, 1), (293, 1), (322, 1), (323, 4), (324, 1), (325, 1), (328, 1), (357, 3), (385, 1), (387, 1), (406, 1), (421, 1), (457, 1), (464, 1), (469, 1), (501, 1), (527, 1), (530, 1), (540, 1), (541, 1), (547, 1), (568, 1), (576, 1), (577, 1), (582, 1), (585, 1), (591, 1), (600, 1), (606, 1), (608, 1), (609, 1), (611, 1), (618, 2), (624, 2), (640, 1), (649, 1), (660, 1), (682, 1), (700, 1), (702, 4), (737, 1), (772, 1), (776, 1), (800, 1), (860, 1), (867, 1), (884, 1), (900, 1), (933, 1), (951, 1), (966, 1), (970, 2), (990, 1), (1005, 1), (1033, 1), (1036, 1), (1073, 1), (1082, 1), (1088, 1), (1093, 1), (1110, 1), (1131, 3), (1192, 1), (1195, 1), (1196, 1), (1223, 1), (1238, 1), (1243, 1), (1245, 1), (1261, 1), (1275, 2), (1295, 1), (1299, 1), (1301, 1), (1330, 1), (1339, 1), (1350, 1), (1386, 3), (1398, 1), (1399, 3), (1405, 1), (1411, 1), (1468, 2), (1469, 1), (1511, 2), (1543, 1), (1564, 1), (1570, 1), (1571, 1), (1572, 1), (1581, 2), (1622, 1), (1639, 1), (1650, 1), (1657, 1), (1658, 1), (1678, 1), (1683, 1), (1721, 3), (1731, 2), (1754, 1), (1789, 1), (1798, 1), (1875, 2), (1876, 1), (1888, 4), (1898, 2), (1920, 1), (1922, 2), (1929, 1), (1952, 1), (2004, 1), (2044, 1), (2072, 1), (2087, 1), (2114, 1), (2160, 1), (2170, 1), (2210, 1), (2222, 1), (2249, 2), (2324, 1), (2384, 1), (2388, 1), (2435, 1), (2441, 9), (2488, 1), (2494, 1), (2545, 1), (2547, 2), (2576, 1), (2586, 2), (2636, 1), (2710, 1), (2714, 1), (2761, 1), (2785, 1), (2801, 1), (2830, 1), (2873, 2), (2892, 1), (2903, 1), (2904, 1), (2917, 1), (2940, 1), (2951, 1), (2969, 1), (2994, 1), (2995, 1), (3002, 2), (3024, 1), (3035, 1), (3131, 1), (3206, 1), (3208, 1), (3219, 1), (3238, 1), (3242, 1), (3277, 1), (3281, 1), (3291, 1), (3306, 1), (3309, 1), (3321, 1), (3327, 1), (3334, 1), (3354, 1), (3389, 1), (3390, 1), (3415, 1), (3519, 1), (3524, 1), (3560, 1), (3589, 1), (3623, 1), (3624, 1), (3669, 1), (3684, 2), (3739, 1), (3748, 1), (3776, 1), (3803, 1), (3804, 1), (3816, 1), (3842, 1), (3910, 1), (3984, 1), (3985, 1), (4035, 2), (4058, 1), (4104, 1), (4123, 1), (4126, 1), (4210, 1), (4282, 1), (4358, 1), (4529, 1), (4565, 1), (4593, 5)], [(85, 1), (103, 1), (106, 1), (127, 1), (130, 6), (143, 1), (149, 1), (157, 1), (166, 2), (180, 2), (219, 1), (234, 1), (284, 1), (310, 1), (332, 2), (349, 1), (357, 2), (369, 1), (378, 1), (430, 1), (453, 1), (488, 1), (505, 2), (534, 1), (548, 1), (553, 2), (582, 1), (604, 2), (625, 1), (636, 1), (701, 1), (702, 1), (727, 1), (737, 2), (776, 1), (789, 1), (800, 5), (862, 1), (869, 1), (882, 2), (907, 1), (933, 1), (1024, 1), (1026, 1), (1053, 10), (1156, 1), (1157, 1), (1192, 1), (1223, 2), (1396, 2), (1398, 2), (1400, 2), (1403, 9), (1408, 1), (1409, 1), (1563, 3), (1570, 1), (1595, 2), (1619, 2), (1679, 1), (1686, 1), (1714, 1), (1743, 1), (1747, 1), (1751, 1), (1757, 1), (1760, 4), (1762, 1), (1903, 1), (1918, 2), (2087, 1), (2103, 4), (2166, 1), (2360, 1), (2368, 2), (2407, 1), (2475, 2), (2487, 4), (2529, 3), (2579, 1), (2586, 3), (2587, 1), (2590, 1), (2608, 1), (2911, 1), (2970, 1), (2971, 1), (3010, 1), (3069, 1), (3294, 1), (3297, 1), (3319, 1), (3410, 5), (3511, 1), (3532, 1), (3590, 1), (4066, 1), (4131, 1), (4164, 1), (4178, 1), (4212, 1), (4341, 1), (4358, 1), (4584, 1), (4589, 3)], [(13, 2), (24, 2), (26, 1), (51, 1), (73, 2), (89, 1), (111, 1), (112, 1), (121, 2), (143, 2), (148, 1), (169, 1), (173, 1), (180, 3), (213, 1), (228, 1), (260, 1), (329, 1), (334, 1), (373, 1), (411, 7), (414, 4), (419, 6), (453, 1), (482, 2), (488, 1), (518, 1), (548, 2), (570, 1), (604, 1), (606, 1), (614, 1), (626, 1), (679, 3), (690, 1), (692, 1), (710, 1), (800, 3), (833, 1), (846, 1), (1098, 1), (1106, 1), (1124, 1), (1141, 1), (1196, 1), (1219, 4), (1299, 1), (1451, 1), (1714, 1), (1721, 1), (1757, 2), (1823, 1), (2028, 1), (2057, 5), (2071, 1), (2129, 1), (2143, 1), (2214, 2), (2413, 1), (2450, 1), (2460, 1), (2607, 1), (2702, 1), (2755, 1), (3009, 2), (3027, 1), (3096, 1), (3097, 1), (3127, 1), (3128, 1), (3262, 1), (3300, 1), (3365, 1), (3377, 2), (3454, 1), (3510, 1), (3586, 1), (3763, 1), (3828, 1), (3863, 1), (3971, 1), (4173, 1), (4175, 1), (4532, 1), (4533, 2), (4543, 1), (4557, 1)], [(30, 1), (35, 1), (106, 1), (140, 2), (157, 2), (213, 3), (219, 1), (252, 2), (286, 3), (341, 1), (349, 1), (353, 1), (362, 1), (378, 7), (461, 1), (489, 1), (521, 1), (550, 2), (604, 1), (620, 4), (626, 1), (670, 1), (672, 1), (753, 1), (761, 1), (776, 2), (782, 3), (794, 1), (800, 3), (806, 2), (846, 1), (869, 1), (887, 1), (894, 2), (1040, 1), (1058, 1), (1060, 1), (1064, 1), (1066, 1), (1082, 1), (1122, 2), (1164, 1), (1192, 1), (1225, 1), (1308, 1), (1385, 1), (1396, 5), (1398, 2), (1400, 1), (1403, 1), (1503, 1), (1511, 1), (1543, 1), (1577, 1), (1650, 1), (1703, 1), (1766, 2), (2188, 1), (2190, 1), (2295, 2), (2353, 1), (2444, 5), (2487, 1), (2628, 2), (2654, 1), (2771, 1), (2838, 1), (2970, 4), (2993, 1), (3229, 1), (3297, 1), (3370, 2), (3529, 5), (3583, 1), (3755, 1), (3988, 1), (3999, 1), (4016, 1), (4155, 8), (4594, 1)], [(29, 1), (39, 1), (73, 1), (87, 1), (121, 6), (149, 1), (169, 4), (219, 1), (225, 1), (228, 1), (229, 3), (232, 1), (238, 6), (245, 1), (250, 1), (277, 2), (304, 2), (353, 2), (357, 1), (362, 3), (403, 1), (411, 1), (420, 2), (450, 4), (465, 1), (543, 2), (557, 1), (582, 1), (598, 1), (608, 4), (632, 1), (657, 1), (684, 1), (695, 2), (769, 1), (776, 1), (782, 1), (795, 1), (800, 4), (847, 1), (894, 1), (908, 2), (963, 1), (1023, 1), (1038, 1), (1084, 2), (1096, 2), (1117, 1), (1131, 1), (1192, 2), (1243, 2), (1253, 1), (1263, 1), (1295, 1), (1399, 4), (1400, 1), (1544, 4), (1547, 1), (1731, 1), (1757, 1), (2011, 1), (2064, 1), (2090, 1), (2091, 1), (2272, 1), (2295, 1), (2304, 1), (2311, 1), (2409, 1), (2440, 1), (2468, 1), (2472, 7), (2487, 2), (2607, 1), (2608, 1), (2635, 1), (2643, 1), (2664, 1), (2687, 1), (2698, 5), (2740, 1), (2841, 1), (2856, 1), (2862, 1), (2924, 1), (2956, 1), (2961, 1), (3009, 1), (3258, 1), (3287, 1), (3305, 4), (3330, 1), (3489, 1), (3612, 1), (3613, 2), (3624, 1), (3703, 1), (3764, 1), (3907, 1), (3913, 1), (3955, 1), (3956, 2), (4119, 3), (4155, 3), (4163, 1), (4531, 1), (4535, 3), (4543, 1), (4576, 1)], [(0, 1), (2, 1), (30, 1), (31, 1), (39, 2), (48, 1), (54, 1), (55, 1), (91, 1), (95, 1), (111, 5), (112, 2), (121, 3), (128, 1), (149, 2), (154, 1), (157, 1), (166, 2), (174, 1), (180, 2), (184, 4), (185, 1), (190, 1), (195, 2), (211, 1), (230, 2), (236, 1), (238, 1), (261, 2), (263, 1), (271, 1), (277, 1), (293, 1), (294, 1), (295, 1), (332, 1), (337, 1), (350, 1), (353, 1), (357, 2), (362, 2), (380, 1), (388, 1), (408, 1), (411, 5), (414, 1), (419, 8), (420, 1), (423, 1), (438, 1), (440, 2), (449, 1), (478, 1), (484, 1), (485, 2), (488, 2), (501, 1), (505, 2), (518, 1), (524, 1), (531, 1), (542, 1), (558, 2), (569, 1), (594, 1), (600, 2), (614, 1), (620, 1), (679, 1), (684, 1), (729, 1), (750, 1), (753, 1), (776, 1), (794, 1), (797, 1), (800, 8), (823, 1), (836, 3), (847, 1), (874, 1), (885, 1), (907, 1), (908, 1), (963, 1), (970, 2), (972, 1), (976, 1), (987, 1), (1021, 2), (1024, 1), (1025, 1), (1033, 1), (1040, 1), (1072, 1), (1106, 1), (1178, 1), (1196, 1), (1208, 1), (1217, 1), (1219, 1), (1225, 3), (1241, 1), (1284, 2), (1301, 2), (1307, 1), (1310, 1), (1318, 1), (1323, 1), (1373, 1), (1397, 1), (1398, 3), (1400, 2), (1457, 1), (1468, 3), (1479, 1), (1490, 2), (1540, 2), (1564, 12), (1581, 1), (1615, 1), (1630, 1), (1657, 4), (1730, 1), (1748, 1), (1757, 1), (1806, 2), (1835, 1), (1869, 1), (1888, 2), (1906, 1), (1941, 1), (2028, 1), (2044, 1), (2057, 2), (2087, 1), (2263, 1), (2279, 3), (2310, 1), (2313, 1), (2315, 1), (2344, 1), (2348, 1), (2368, 1), (2435, 1), (2469, 1), (2487, 1), (2496, 1), (2532, 1), (2558, 1), (2607, 2), (2616, 1), (2630, 2), (2732, 1), (2769, 2), (2807, 1), (2820, 1), (2822, 3), (2866, 1), (2869, 1), (2923, 4), (2967, 1), (3013, 1), (3032, 1), (3150, 1), (3234, 1), (3258, 1), (3276, 1), (3288, 1), (3291, 1), (3343, 2), (3387, 1), (3398, 1), (3488, 1), (3523, 1), (3534, 1), (3541, 1), (3556, 3), (3583, 1), (3697, 1), (3748, 1), (3789, 1), (3889, 1), (3904, 1), (3979, 1), (4083, 3), (4164, 1), (4165, 2), (4189, 4), (4300, 1), (4521, 1), (4533, 1), (4537, 2), (4551, 2)], [(7, 1), (39, 1), (40, 1), (82, 3), (157, 1), (159, 1), (169, 1), (180, 1), (211, 1), (238, 2), (250, 1), (346, 4), (348, 1), (353, 1), (380, 1), (420, 1), (466, 1), (467, 2), (468, 1), (483, 1), (488, 2), (517, 1), (524, 1), (546, 1), (553, 1), (583, 3), (595, 1), (606, 1), (607, 1), (618, 2), (623, 1), (635, 1), (698, 1), (716, 1), (722, 1), (757, 3), (759, 1), (761, 1), (782, 1), (795, 1), (800, 2), (803, 1), (833, 1), (861, 1), (908, 1), (983, 1), (1014, 1), (1024, 1), (1071, 1), (1131, 2), (1179, 1), (1230, 1), (1290, 1), (1300, 1), (1304, 1), (1326, 1), (1341, 1), (1370, 1), (1381, 1), (1391, 1), (1399, 2), (1564, 1), (1707, 1), (1743, 1), (1757, 1), (1787, 1), (1886, 1), (1995, 1), (2044, 1), (2214, 1), (2215, 1), (2255, 1), (2300, 1), (2441, 9), (2472, 2), (2546, 1), (2702, 2), (2997, 2), (3036, 1), (3037, 1), (3038, 9), (3040, 1), (3321, 1), (3322, 1), (3398, 2), (3519, 1), (3622, 1), (3703, 1), (3860, 1), (3900, 1), (3926, 1), (3968, 1), (4120, 1), (4142, 1), (4154, 1), (4175, 1), (4212, 2), (4273, 5), (4530, 1), (4577, 1), (4581, 1), (4590, 1), (4591, 5), (4595, 1)], [(39, 1), (40, 1), (44, 2), (54, 1), (55, 1), (95, 2), (96, 1), (97, 1), (104, 1), (130, 1), (144, 1), (148, 6), (182, 2), (187, 1), (202, 1), (203, 1), (219, 1), (225, 1), (231, 1), (250, 1), (252, 1), (277, 1), (278, 1), (284, 1), (285, 1), (324, 2), (353, 1), (358, 1), (360, 2), (377, 1), (380, 1), (414, 5), (416, 1), (420, 2), (435, 1), (449, 1), (488, 1), (540, 1), (541, 2), (548, 2), (553, 1), (559, 1), (570, 1), (579, 1), (586, 1), (601, 1), (608, 1), (610, 1), (625, 3), (671, 1), (672, 1), (679, 1), (684, 1), (696, 1), (716, 2), (724, 2), (741, 1), (750, 3), (778, 4), (790, 1), (791, 7), (798, 5), (800, 1), (804, 1), (806, 6), (844, 1), (846, 1), (869, 2), (874, 2), (887, 1), (919, 1), (933, 3), (994, 1), (1005, 1), (1036, 1), (1057, 1), (1068, 1), (1071, 1), (1080, 1), (1081, 1), (1119, 1), (1122, 2), (1192, 6), (1196, 1), (1245, 1), (1264, 1), (1272, 1), (1310, 1), (1314, 1), (1323, 1), (1381, 1), (1382, 1), (1400, 3), (1408, 1), (1413, 1), (1502, 1), (1532, 2), (1551, 1), (1556, 1), (1608, 1), (1702, 2), (1728, 1), (1740, 2), (1747, 2), (1783, 1), (1807, 1), (1883, 1), (1888, 1), (1931, 1), (1952, 1), (1972, 1), (2005, 2), (2035, 1), (2064, 1), (2103, 1), (2148, 1), (2195, 1), (2242, 1), (2281, 1), (2355, 2), (2362, 3), (2389, 2), (2480, 1), (2482, 1), (2487, 2), (2495, 1), (2521, 1), (2547, 1), (2586, 1), (2595, 2), (2607, 1), (2616, 1), (2703, 1), (2795, 1), (2799, 1), (3013, 3), (3272, 1), (3275, 1), (3356, 1), (3398, 2), (3511, 1), (3522, 1), (3599, 1), (3608, 1), (3673, 1), (3776, 1), (3783, 1), (3932, 1), (3966, 1), (4465, 1), (4552, 1), (4586, 1)], [(9, 1), (13, 1), (26, 1), (27, 2), (37, 1), (48, 1), (54, 1), (74, 1), (82, 1), (85, 1), (95, 1), (106, 1), (112, 4), (154, 1), (180, 1), (198, 1), (214, 1), (238, 1), (246, 1), (247, 1), (252, 1), (294, 2), (311, 1), (323, 2), (358, 1), (360, 1), (362, 1), (423, 1), (431, 1), (448, 1), (558, 1), (559, 1), (567, 1), (568, 1), (582, 1), (595, 1), (608, 2), (618, 1), (641, 1), (656, 1), (671, 1), (711, 1), (737, 1), (757, 9), (776, 2), (795, 1), (832, 1), (833, 1), (915, 3), (919, 1), (963, 1), (1024, 1), (1038, 1), (1122, 1), (1131, 2), (1147, 1), (1163, 1), (1166, 1), (1169, 2), (1195, 3), (1218, 1), (1241, 1), (1261, 1), (1294, 1), (1314, 1), (1326, 2), (1399, 1), (1428, 1), (1511, 1), (1529, 1), (1546, 2), (1570, 1), (1676, 1), (1688, 4), (1692, 1), (1721, 2), (1756, 3), (1760, 1), (1817, 1), (1877, 1), (1887, 2), (1888, 1), (1898, 1), (1922, 1), (1950, 2), (2056, 4), (2096, 1), (2210, 1), (2282, 1), (2410, 1), (2441, 6), (2449, 1), (2537, 1), (2574, 1), (2590, 1), (2687, 2), (2699, 1), (2873, 1), (2942, 1), (2997, 1), (3013, 1), (3038, 2), (3132, 1), (3174, 1), (3208, 1), (3321, 1), (3426, 1), (3640, 1), (3683, 1), (3748, 2), (3750, 1), (3769, 1), (3789, 1), (3811, 1), (3815, 1), (3853, 1), (3897, 1), (3966, 1), (3972, 1), (4042, 1), (4055, 1), (4186, 1), (4273, 1), (4528, 1), (4549, 1), (4570, 1), (4571, 3), (4593, 1)], [(0, 3), (1, 2), (2, 3), (9, 1), (27, 1), (44, 1), (51, 1), (55, 1), (60, 1), (91, 2), (106, 1), (109, 1), (111, 2), (119, 1), (128, 1), (143, 1), (149, 1), (150, 1), (154, 1), (157, 1), (159, 1), (252, 1), (255, 1), (258, 1), (295, 1), (302, 1), (324, 1), (346, 1), (353, 1), (377, 1), (403, 1), (411, 3), (416, 1), (435, 1), (475, 1), (478, 1), (488, 7), (504, 1), (517, 1), (526, 1), (532, 1), (539, 1), (547, 1), (553, 1), (559, 1), (569, 1), (570, 1), (571, 1), (574, 1), (579, 2), (580, 1), (612, 3), (613, 1), (615, 2), (623, 1), (655, 1), (671, 2), (672, 1), (676, 1), (679, 1), (718, 1), (722, 1), (757, 1), (762, 1), (769, 1), (782, 1), (794, 1), (795, 1), (800, 3), (803, 1), (806, 1), (832, 2), (836, 1), (841, 1), (862, 1), (869, 2), (872, 1), (919, 1), (1014, 1), (1053, 1), (1081, 1), (1124, 1), (1208, 1), (1219, 1), (1284, 2), (1295, 2), (1301, 1), (1323, 1), (1346, 1), (1398, 2), (1399, 6), (1511, 1), (1537, 1), (1595, 1), (1686, 1), (1721, 1), (1725, 1), (1757, 1), (1760, 3), (1782, 2), (1972, 2), (2044, 1), (2143, 1), (2288, 2), (2342, 1), (2366, 1), (2375, 2), (2431, 3), (2467, 2), (2469, 1), (2472, 6), (2630, 1), (2660, 1), (2690, 1), (2703, 2), (2748, 1), (2753, 1), (2830, 1), (2831, 1), (2923, 1), (2952, 1), (3012, 1), (3096, 1), (3127, 1), (3305, 1), (3306, 1), (3322, 1), (3343, 1), (3385, 1), (3469, 1), (3505, 1), (3561, 1), (3613, 6), (3631, 2), (3635, 1), (3774, 1), (3900, 2), (3931, 4), (3955, 5), (3956, 6), (3957, 2), (4155, 1), (4163, 2), (4212, 2), (4323, 1), (4332, 1), (4527, 1), (4532, 1), (4541, 1), (4543, 4), (4558, 2), (4596, 1)], [(2, 1), (31, 1), (39, 1), (103, 1), (112, 1), (151, 1), (169, 1), (198, 1), (219, 1), (232, 1), (260, 1), (263, 2), (266, 2), (272, 1), (278, 1), (319, 1), (343, 1), (353, 1), (388, 1), (416, 4), (418, 1), (476, 1), (488, 2), (500, 1), (525, 1), (528, 1), (531, 1), (553, 1), (557, 1), (608, 1), (716, 1), (777, 1), (794, 1), (800, 1), (805, 1), (869, 1), (899, 1), (908, 2), (913, 1), (915, 1), (970, 1), (974, 1), (1065, 1), (1079, 2), (1097, 3), (1131, 1), (1180, 1), (1185, 1), (1197, 1), (1250, 1), (1305, 1), (1330, 6), (1375, 1), (1457, 1), (1500, 2), (1521, 1), (1546, 1), (1571, 1), (1595, 1), (1672, 1), (1753, 1), (1819, 1), (1906, 1), (1920, 1), (1929, 7), (1952, 1), (1983, 2), (1984, 1), (2034, 1), (2111, 1), (2159, 1), (2214, 1), (2405, 1), (2461, 1), (2467, 3), (2512, 7), (2728, 1), (2773, 3), (2822, 5), (2859, 1), (2906, 1), (3073, 3), (3111, 1), (3171, 2), (3321, 1), (3505, 1), (3623, 1), (3699, 6), (3721, 1), (3813, 1), (3983, 1), (4085, 1), (4180, 5), (4186, 1), (4534, 1)], [(18, 1), (25, 1), (39, 1), (112, 1), (121, 10), (149, 3), (150, 1), (157, 1), (162, 2), (169, 3), (173, 2), (277, 1), (293, 1), (294, 1), (297, 1), (304, 1), (323, 1), (325, 1), (329, 1), (339, 2), (374, 1), (409, 1), (411, 3), (414, 2), (416, 3), (450, 1), (469, 1), (471, 1), (483, 2), (488, 2), (516, 1), (540, 1), (547, 1), (548, 2), (550, 1), (575, 1), (582, 1), (589, 11), (608, 1), (655, 1), (676, 1), (757, 2), (761, 4), (772, 1), (776, 4), (794, 1), (802, 1), (803, 1), (833, 1), (836, 1), (847, 1), (851, 1), (862, 1), (899, 1), (908, 1), (963, 1), (968, 2), (1001, 1), (1081, 1), (1084, 1), (1093, 1), (1097, 1), (1117, 1), (1131, 1), (1191, 1), (1192, 1), (1195, 1), (1204, 1), (1219, 5), (1250, 1), (1275, 3), (1281, 2), (1296, 2), (1301, 1), (1326, 1), (1397, 1), (1443, 1), (1529, 1), (1534, 1), (1550, 3), (1580, 1), (1650, 1), (1722, 1), (1760, 1), (1882, 1), (1888, 1), (1889, 1), (1899, 1), (1995, 1), (2056, 1), (2148, 1), (2159, 1), (2441, 5), (2463, 1), (2468, 1), (2471, 2), (2472, 2), (2511, 1), (2607, 3), (2616, 1), (2716, 1), (2811, 1), (2910, 2), (3036, 1), (3073, 1), (3305, 1), (3321, 1), (3327, 1), (3537, 1), (3614, 1), (3623, 2), (3636, 2), (3739, 1), (3861, 1), (4013, 1), (4073, 8), (4119, 1), (4120, 1), (4161, 1), (4272, 1), (4273, 1), (4360, 1), (4529, 2), (4533, 5), (4535, 1), (4557, 1), (4577, 1)], [(0, 2), (35, 1), (73, 1), (81, 2), (82, 2), (93, 1), (119, 1), (121, 1), (145, 1), (148, 1), (149, 1), (171, 1), (180, 2), (186, 1), (216, 1), (224, 1), (260, 2), (285, 1), (310, 2), (315, 1), (333, 1), (342, 1), (346, 2), (358, 1), (430, 1), (467, 1), (488, 2), (540, 2), (548, 1), (559, 2), (586, 1), (594, 1), (608, 3), (623, 1), (671, 1), (676, 1), (695, 1), (716, 1), (733, 1), (757, 2), (776, 1), (802, 1), (844, 1), (869, 4), (985, 1), (987, 1), (1014, 1), (1021, 1), (1024, 1), (1031, 1), (1032, 1), (1053, 7), (1131, 1), (1157, 1), (1208, 1), (1259, 1), (1270, 1), (1301, 1), (1306, 1), (1323, 1), (1373, 1), (1444, 1), (1450, 1), (1511, 1), (1535, 1), (1547, 1), (1554, 1), (1563, 4), (1570, 3), (1688, 1), (1729, 1), (1756, 2), (1762, 1), (1896, 1), (1976, 1), (1988, 1), (2104, 1), (2190, 1), (2325, 1), (2421, 1), (2441, 6), (2576, 3), (2683, 1), (2752, 1), (2770, 1), (3032, 1), (3034, 1), (3036, 2), (3038, 3), (3040, 1), (3316, 1), (3322, 2), (3330, 2), (3496, 1), (3577, 1), (3583, 1), (3616, 1), (3640, 1), (3761, 1), (3910, 1), (4064, 1), (4116, 1), (4170, 1), (4335, 1), (4338, 4), (4344, 1), (4358, 1), (4530, 1), (4570, 1), (4571, 6), (4577, 1), (4590, 3)], [(73, 3), (77, 1), (121, 4), (145, 1), (150, 1), (173, 1), (219, 2), (248, 1), (270, 1), (292, 1), (293, 1), (303, 1), (355, 3), (357, 1), (399, 1), (431, 2), (438, 1), (450, 1), (467, 1), (474, 1), (479, 1), (532, 4), (535, 1), (540, 1), (544, 1), (573, 1), (608, 1), (625, 1), (657, 1), (700, 1), (716, 1), (776, 1), (800, 3), (802, 1), (806, 4), (814, 1), (831, 1), (862, 2), (869, 4), (886, 1), (887, 1), (894, 3), (912, 1), (1009, 1), (1020, 1), (1081, 4), (1095, 1), (1150, 1), (1157, 1), (1192, 1), (1301, 2), (1324, 1), (1379, 1), (1400, 2), (1439, 1), (1445, 1), (1459, 1), (1465, 1), (1511, 1), (1544, 1), (1546, 1), (1657, 1), (1677, 1), (1721, 5), (1728, 1), (1757, 1), (1760, 1), (1875, 3), (1896, 1), (1903, 1), (1922, 1), (2019, 1), (2044, 3), (2052, 2), (2078, 1), (2103, 2), (2106, 2), (2108, 5), (2277, 1), (2283, 1), (2324, 1), (2344, 1), (2356, 1), (2382, 1), (2487, 1), (2488, 1), (2505, 1), (2520, 1), (2599, 1), (3013, 1), (3037, 1), (3092, 1), (3095, 3), (3137, 1), (3163, 1), (3381, 1), (3409, 1), (3440, 1), (3498, 1), (3530, 1), (3589, 1), (3593, 1), (3699, 1), (3807, 1), (3937, 2), (3998, 1), (4073, 1), (4164, 1), (4176, 6), (4417, 1), (4592, 1)], [(18, 1), (42, 1), (96, 1), (99, 1), (102, 1), (108, 1), (112, 6), (169, 4), (211, 1), (228, 1), (260, 1), (284, 2), (329, 1), (334, 1), (371, 1), (414, 8), (445, 1), (460, 1), (477, 1), (508, 1), (544, 1), (547, 1), (548, 4), (550, 1), (557, 1), (644, 4), (666, 1), (676, 1), (727, 4), (746, 1), (753, 1), (776, 3), (794, 1), (834, 2), (844, 1), (917, 1), (1096, 1), (1122, 3), (1180, 1), (1215, 2), (1216, 1), (1275, 1), (1291, 1), (1301, 1), (1325, 1), (1378, 1), (1418, 2), (1526, 1), (1536, 2), (1578, 2), (1581, 4), (1663, 1), (1689, 1), (1724, 1), (1756, 1), (1770, 1), (1865, 1), (1898, 1), (1907, 1), (1986, 1), (2187, 1), (2195, 1), (2202, 2), (2214, 1), (2215, 2), (2241, 2), (2249, 1), (2334, 3), (2370, 3), (2474, 1), (2506, 1), (2621, 3), (2643, 1), (2660, 1), (2681, 1), (2698, 2), (2815, 1), (2951, 1), (2991, 1), (3143, 1), (3258, 1), (3422, 1), (3426, 1), (3482, 1), (3549, 1), (3578, 2), (3595, 4), (3637, 1), (3677, 1), (3796, 3), (4181, 1), (4361, 1), (4568, 1)]]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "def bigrams(words, bi_min=15, tri_min=10):\n",
    "    bigram = gensim.models.Phrases(words, min_count = bi_min)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return bigram_mod\n",
    "\n",
    "def get_corpus(texts, bigram_mod):\n",
    "    bigram_mod = bigrams(texts)\n",
    "    bigram = [bigram_mod[text] for text in texts]\n",
    "    id2word = gensim.corpora.Dictionary(bigram)\n",
    "    id2word.filter_extremes(no_below=10, no_above=0.35)\n",
    "    id2word.compactify()\n",
    "    corpus = [id2word.doc2bow(text) for text in bigram]\n",
    "    return corpus, id2word, bigram\n",
    "\n",
    "bigram_mod = bigrams(texts)\n",
    "corpus, dictionary, bigram = get_corpus(texts, bigram_mod)\n",
    "print(corpus)"
   ]
  },
  {
   "source": [
    "# Use HDP to auto-get topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, '0.007*peopl + 0.005*game + 0.004*plai + 0.004*work + 0.003*win + 0.003*music + 0.003*film + 0.003*number + 0.003*sai + 0.003*set'), (1, '0.003*labour + 0.003*blair + 0.003*brown + 0.002*govern + 0.002*plan + 0.002*compani + 0.002*firm + 0.002*indian + 0.002*accord + 0.002*india'), (2, '0.002*profit + 0.002*firm + 0.002*sale + 0.002*compani + 0.002*film + 0.002*gazprom + 0.002*govern + 0.002*produc + 0.001*wine + 0.001*japan'), (3, '0.002*bank + 0.002*govern + 0.002*peopl + 0.002*sharp + 0.002*rate + 0.001*remain + 0.001*england + 0.001*compani + 0.001*journei + 0.001*british'), (4, '0.002*market + 0.002*share + 0.002*lord + 0.002*countri + 0.001*expect + 0.001*govern + 0.001*risen + 0.001*warn + 0.001*asia + 0.001*compani'), (5, '0.002*britain + 0.002*consum_spend + 0.002*trade + 0.002*telecom + 0.002*data + 0.001*group + 0.001*peopl + 0.001*plan + 0.001*govern + 0.001*september'), (6, '0.003*film + 0.002*dollar + 0.002*best + 0.002*martin_scorsese + 0.002*director + 0.002*win + 0.002*star + 0.002*charl + 0.002*actress + 0.001*close'), (7, '0.002*bn + 0.002*sale + 0.002*local_govern + 0.002*deal + 0.002*tax + 0.002*firm + 0.002*work + 0.002*india + 0.001*oscars + 0.001*chines'), (8, '0.003*rate + 0.003*growth + 0.002*rise + 0.002*trade + 0.002*despit + 0.002*month + 0.002*sale + 0.002*quarter + 0.002*data + 0.002*grow'), (9, '0.003*price + 0.002*chariti + 0.002*market + 0.002*oil + 0.002*requir + 0.002*bn + 0.002*firm + 0.002*crude + 0.002*member + 0.002*profit'), (10, '0.002*sale + 0.002*labour + 0.002*tottenham + 0.002*slowli + 0.002*role + 0.001*airlin + 0.001*charg + 0.001*win + 0.001*deem + 0.001*passeng'), (11, '0.002*film + 0.002*elect + 0.002*econom + 0.002*capabl + 0.001*greg + 0.001*school + 0.001*emploi + 0.001*record + 0.001*nation + 0.001*tie'), (12, '0.002*crown + 0.001*fall + 0.001*prosper + 0.001*georgia + 0.001*suspects + 0.001*heart + 0.001*export + 0.001*arbitr + 0.001*gloucest + 0.001*compli'), (13, '0.002*film + 0.002*manufactur + 0.002*confer + 0.002*rio + 0.002*redund + 0.002*figur + 0.002*tour + 0.002*intens + 0.001*children + 0.001*displai'), (14, '0.003*figur + 0.002*quarter + 0.002*celtic + 0.002*smart + 0.002*wheel + 0.002*firmli + 0.001*democraci + 0.001*loss + 0.001*airport + 0.001*factor'), (15, '0.002*sexual + 0.002*cup_final + 0.002*lse + 0.002*report + 0.002*jean + 0.002*conclud + 0.002*lisbon + 0.002*consol + 0.002*accord + 0.001*unacceptable'), (16, '0.002*current + 0.002*job + 0.002*niro + 0.002*ga + 0.002*class + 0.002*training + 0.002*project + 0.002*motor + 0.001*serious + 0.001*australia'), (17, '0.002*simul + 0.002*storag + 0.002*remot + 0.001*compani + 0.001*public_services + 0.001*governments + 0.001*busi + 0.001*files + 0.001*whip + 0.001*midfield'), (18, '0.002*sharpli + 0.002*built + 0.001*lewis_fr + 0.001*told_reuter + 0.001*matt + 0.001*nomin + 0.001*market + 0.001*minutes + 0.001*improv + 0.001*dedic'), (19, '0.001*audit + 0.001*auto + 0.001*famili + 0.001*nativ + 0.001*iraq + 0.001*drink + 0.001*leigh + 0.001*unaccept + 0.001*bring + 0.001*king')]\n"
     ]
    }
   ],
   "source": [
    "def get_hdp_model(corpus, dictionary):\n",
    "    Hdp_model = gensim.models.hdpmodel.HdpModel(corpus=corpus, id2word=dictionary)\n",
    "    return Hdp_model\n",
    "\n",
    "hdp_model = get_hdp_model(corpus, dictionary)\n",
    "topics = hdp_model.print_topics()\n",
    "print(topics)"
   ]
  },
  {
   "source": [
    "# Create LDA model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LdaModel(num_terms=4600, num_topics=5, decay=0.5, chunksize=100)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gensim\n",
    "import warnings\n",
    "import logging # This allows for seeing if the model converges. A log file is created.\n",
    "logging.basicConfig(filename='lda_model.log', format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def create_lda_model(corpus, dictionary, num_topics):\n",
    "    if not os.path.exists(\"models\"):\n",
    "        os.mkdir(\"models\")\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        lda_train = gensim.models.ldamulticore.LdaMulticore(\n",
    "                            corpus=corpus,\n",
    "                            num_topics=num_topics,\n",
    "                            id2word=dictionary,\n",
    "                            chunksize=100,\n",
    "                            workers=7, # Num. Processing Cores - 1\n",
    "                            passes=50,\n",
    "                            eval_every = 1,\n",
    "                            per_word_topics=True)\n",
    "        lda_train.save(os.path.join(\"models\", \"lda_train.model\"))\n",
    "    return lda_train\n",
    "\n",
    "train_lda_model = create_lda_model(corpus, dictionary, len(CATEGORIES))\n",
    "print(train_lda_model)"
   ]
  },
  {
   "source": [
    "## Print topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.013*\"site\" + 0.013*\"peopl\" + 0.012*\"net\" + 0.012*\"user\" + 0.009*\"firm\" + 0.009*\"softwar\" + 0.009*\"mail\" + 0.008*\"web\" + 0.008*\"secur\" + 0.007*\"blog\" + 0.007*\"attack\" + 0.007*\"microsoft\" + 0.007*\"compani\" + 0.007*\"file\" + 0.007*\"internet\"'),\n",
       " (1,\n",
       "  '0.008*\"govern\" + 0.008*\"labour\" + 0.007*\"peopl\" + 0.006*\"plan\" + 0.006*\"sai\" + 0.005*\"parti\" + 0.005*\"elect\" + 0.004*\"blair\" + 0.004*\"public\" + 0.004*\"work\" + 0.004*\"tori\" + 0.004*\"brown\" + 0.004*\"issu\" + 0.004*\"claim\" + 0.004*\"law\"'),\n",
       " (2,\n",
       "  '0.008*\"firm\" + 0.008*\"compani\" + 0.007*\"market\" + 0.007*\"bn\" + 0.006*\"sale\" + 0.006*\"china\" + 0.006*\"share\" + 0.006*\"bank\" + 0.006*\"growth\" + 0.006*\"report\" + 0.005*\"rise\" + 0.005*\"rate\" + 0.005*\"month\" + 0.005*\"expect\" + 0.005*\"analyst\"'),\n",
       " (3,\n",
       "  '0.009*\"plai\" + 0.009*\"game\" + 0.009*\"win\" + 0.008*\"film\" + 0.006*\"best\" + 0.005*\"england\" + 0.005*\"player\" + 0.005*\"star\" + 0.005*\"award\" + 0.004*\"team\" + 0.004*\"club\" + 0.004*\"set\" + 0.004*\"match\" + 0.004*\"good\" + 0.004*\"includ\"'),\n",
       " (4,\n",
       "  '0.013*\"peopl\" + 0.013*\"game\" + 0.011*\"technolog\" + 0.009*\"music\" + 0.008*\"mobil\" + 0.008*\"digit\" + 0.006*\"work\" + 0.006*\"broadband\" + 0.006*\"phone\" + 0.005*\"market\" + 0.005*\"wai\" + 0.005*\"servic\" + 0.005*\"video\" + 0.005*\"gadget\" + 0.005*\"offer\"')]"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "train_lda_model.print_topics(len(CATEGORIES),num_words=15)"
   ]
  },
  {
   "source": [
    "# Supervised Training\n",
    "\n",
    "## Get Feature Vectors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_feature_vectors(texts: list, corpus, lda_model):\n",
    "    train_vecs = []\n",
    "    for i in range(len(texts)):\n",
    "        top_topics = lda_model.get_document_topics(corpus[i],minimum_probability=0.0)  \n",
    "        topic_vec = [top_topics[i][1] for i in range(len(CATEGORIES))]\n",
    "        topic_vec.append(len(texts))\n",
    "        topic_vec.append(len(texts[i]))\n",
    "        train_vecs.append(topic_vec)\n",
    "    return train_vecs"
   ]
  },
  {
   "source": [
    "## Prepare dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1780 1780\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "texts_corpus_zip = list(zip(texts, corpus))\n",
    "\n",
    "train_texts, test_texts, train_categories, test_categories = train_test_split(texts, categories, test_size=0.2, shuffle=True)\n",
    "\n",
    "feature_vectors = get_feature_vectors(train_texts, corpus, train_lda_model)\n",
    "print(len(feature_vectors), len(train_categories))"
   ]
  },
  {
   "source": [
    "## Neural Network Multi-Class Classifier Model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "def create_model(activation=\"relu\", optimizer=\"adam\", dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=len(CATEGORIES)+2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(64, input_dim=len(CATEGORIES)+2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(256, input_dim=len(CATEGORIES)+2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(128, input_dim=len(CATEGORIES)+2, activation=activation))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(len(CATEGORIES), activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "OPTIMIZERS = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "ACTIVATION = ['relu', 'tanh', 'sigmoid', 'linear']\n",
    "BATCH_SIZE = [5, 10, 20, 30, 40, 50]\n",
    "EPOCHS = [10, 50, 100]\n",
    "DROPOUT = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "param_grid = {\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"optimizer\": OPTIMIZERS,\n",
    "    \"dropout_rate\": DROPOUT,\n",
    "    \"activation\": ACTIVATION,\n",
    "}\n",
    "\n",
    "def train(train_vecs, targets):\n",
    "    X = np.array(train_vecs)\n",
    "    Y = np_utils.to_categorical(np.array(targets))\n",
    "\n",
    "    model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=10, verbose=5)\n",
    "\n",
    "    grid_result = grid.fit(X, Y)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "    # kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    # acc_per_fold = []\n",
    "    # loss_per_fold = []\n",
    "\n",
    "    # for train_index, val_index in kf.split(X, y):\n",
    "    #     x_train = X[train_index]\n",
    "    #     y_train = y[train_index]\n",
    "\n",
    "    #     model.fit(x_train, y_train, epochs=100, batch_size=5)\n",
    "    #     scores = model.evaluate(X[val_index], y[val_index], verbose=0)\n",
    "    #     print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]:.6f}; {model.metrics_names[1]} of {scores[1]*100:.3f}%')\n",
    "    #     acc_per_fold.append(scores[1])\n",
    "    #     loss_per_fold.append(scores[0])\n",
    "    #     fold_no += 1\n",
    "\n",
    "    # print(\"Mean Loss: {:.6f} Mean Accuracy: {:.3f}\".format(np.mean(acc_per_fold), np.mean(loss_per_fold)))\n",
    "\n",
    "    best_model = grid_result.best_estimator_\n",
    "    best_model.save(os.path.join(\"models\", \"classifier.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 3024 candidates, totalling 30240 fits\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-7be4b36b4a2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-184-1057adffdecf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_vecs, targets)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/capstone-topic-modelling/venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/capstone-topic-modelling/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/capstone-topic-modelling/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/capstone-topic-modelling/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/capstone-topic-modelling/venv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/capstone-topic-modelling/venv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git/capstone-topic-modelling/venv/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(feature_vectors, train_categories)"
   ]
  },
  {
   "source": [
    "# Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from keras.models import load_model\n",
    "\n",
    "test_feature_vectors = get_feature_vectors(test_texts, corpus, train_lda_model) # Important to use the same LDA model\n",
    "X = np.array(test_feature_vectors)\n",
    "Y = np_utils.to_categorical(np.array(test_categories))\n",
    "\n",
    "# Load model\n",
    "model = load_model(os.path.join(\"models\", \"classifier.pth\"))\n",
    "\n",
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.22782992 0.1724608  0.18308431 0.23607926 0.1805457 ]\n [0.22782992 0.1724608  0.18308431 0.23607926 0.1805457 ]\n [0.22782992 0.1724608  0.18308431 0.23607926 0.1805457 ]\n ...\n [0.22782992 0.1724608  0.18308431 0.23607926 0.1805457 ]\n [0.22782992 0.1724608  0.18308431 0.23607926 0.1805457 ]\n [0.22782992 0.1724608  0.18308431 0.23607926 0.18054572]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "source": [
    "print(y_pred)\n",
    "y_pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 3, 0, 3, 0, 4, 2, 3, 0, 4, 1, 2, 2, 1, 3, 2, 1, 1, 1, 3, 4, 2,\n",
       "       1, 1, 1, 1, 1, 1, 2, 0, 0, 1, 2, 3, 2, 1, 0, 2, 1, 3, 4, 2, 0, 3,\n",
       "       1, 0, 2, 0, 3, 1, 4, 1, 2, 1, 3, 1, 0, 1, 4, 4, 4, 4, 4, 4, 2, 4,\n",
       "       4, 0, 2, 3, 3, 0, 4, 3, 3, 2, 0, 3, 4, 0, 0, 3, 0, 3, 0, 2, 2, 1,\n",
       "       1, 2, 4, 3, 3, 4, 0, 1, 2, 3, 2, 1, 4, 3, 4, 2, 2, 2, 1, 2, 0, 2,\n",
       "       2, 3, 1, 1, 3, 1, 0, 4, 3, 2, 3, 0, 0, 4, 0, 0, 2, 4, 2, 0, 1, 3,\n",
       "       2, 0, 3, 1, 3, 1, 2, 2, 3, 3, 4, 3, 3, 0, 2, 4, 0, 2, 0, 0, 0, 0,\n",
       "       1, 4, 0, 3, 3, 1, 1, 2, 4, 3, 2, 4, 1, 0, 4, 2, 4, 3, 3, 0, 3, 1,\n",
       "       0, 0, 2, 2, 2, 3, 0, 4, 1, 3, 3, 2, 1, 3, 1, 1, 4, 4, 2, 4, 1, 3,\n",
       "       2, 3, 3, 0, 1, 3, 4, 2, 2, 0, 0, 4, 2, 2, 2, 4, 3, 0, 0, 0, 2, 1,\n",
       "       2, 4, 0, 3, 4, 4, 2, 3, 0, 2, 3, 2, 1, 0, 0, 4, 2, 4, 1, 2, 1, 0,\n",
       "       2, 0, 1, 3, 0, 0, 4, 0, 3, 4, 4, 2, 0, 3, 3, 4, 1, 1, 0, 0, 3, 4,\n",
       "       2, 4, 0, 1, 2, 4, 4, 0, 2, 4, 2, 0, 4, 1, 0, 2, 2, 0, 0, 3, 2, 2,\n",
       "       3, 0, 2, 2, 0, 4, 2, 2, 1, 2, 1, 3, 2, 4, 0, 0, 2, 3, 2, 1, 4, 0,\n",
       "       1, 0, 3, 2, 3, 0, 4, 3, 4, 2, 3, 1, 0, 0, 0, 2, 2, 3, 2, 3, 3, 1,\n",
       "       3, 0, 4, 3, 3, 1, 1, 0, 0, 1, 1, 1, 1, 0, 4, 0, 2, 0, 3, 3, 3, 0,\n",
       "       3, 1, 0, 0, 1, 4, 1, 1, 3, 0, 1, 1, 1, 3, 0, 4, 0, 1, 2, 4, 3, 0,\n",
       "       3, 2, 4, 3, 0, 3, 3, 2, 1, 2, 2, 0, 3, 0, 3, 4, 2, 0, 4, 1, 0, 3,\n",
       "       0, 1, 0, 0, 0, 4, 0, 2, 1, 3, 2, 2, 1, 4, 4, 0, 4, 3, 0, 3, 4, 0,\n",
       "       4, 0, 2, 4, 1, 3, 1, 4, 4, 0, 1, 0, 2, 4, 4, 3, 0, 4, 4, 0, 4, 3,\n",
       "       3, 4, 0, 3, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "np.array(test_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}